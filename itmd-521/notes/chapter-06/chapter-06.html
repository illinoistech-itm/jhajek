<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Chapter 06" />
  <title>Spark the Definitive Guide 2nd Edition</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Spark the Definitive Guide 2nd Edition</h1>
  <p class="author">
Chapter 06
  </p>
  <p class="date">Working With Different Types of Data</p>
</div>
<div id="basic-structured-operations" class="title-slide slide section level1"><h1>Basic Structured Operations</h1></div><div id="text-book" class="slide section level2">
<h1>Text Book</h1>
<div class="figure">
<img src="images/spark-book.png" title="Spark TextBook" alt="itmd-521 textbook" />
<p class="caption"><em>itmd-521 textbook</em></p>
</div>
</div><div id="objectives-and-outcomes" class="slide section level2">
<h1>Objectives and Outcomes</h1>
<ul class="incremental">
<li>Understand how to build expressions using typed data</li>
<li>Understand how to use:
<ul class="incremental">
<li>Booleans</li>
<li>Numbers</li>
<li>Strings</li>
<li>Dates and Timestamps</li>
<li>Nulls</li>
<li>Complex and user types</li>
</ul></li>
</ul>
</div><div id="review" class="slide section level2">
<h1>Review</h1>
<ul class="incremental">
<li>So far:
<ul class="incremental">
<li>We covered basic DataFrame operations.</li>
<li>We learned the simple concepts and tools that you will need to be successful with Spark DataFrames</li>
<li>We learned what an expression is</li>
<li>We learned the difference between Select and SelectExpr</li>
<li>We learned how to add columns and rows to a DataFrame</li>
<li>We learned how to take random samples from DataFrames</li>
</ul></li>
</ul>
</div><div id="api-documentation" class="slide section level2">
<h1>API Documentation</h1>
<ul class="incremental">
<li>Where do all of these functions come from?
<ul class="incremental">
<li><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset" title="Spark Documentation for Dataset">There is Spark documentation for Datasets in Scala</a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/" title="Python API">Python API</a></li>
<li>A DataFrame is just a Dataset of type <code>Row</code> so you’ll end up looking at the Dataset methods</li>
</ul></li>
<li>Column Methods such as <code>alias</code> or <code>contains</code>
<ul class="incremental">
<li><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column" title="Spark Documentation for Columns">Column</a></li>
<li><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$" title="Spark Documentation for sql functions"><em>org.apache.spark.sql.functions</em></a></li>
</ul></li>
<li>All of these tools exist to transform rows of data in one format or structure to another.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1">df <span class="op">=</span> spark.read.<span class="bu">format</span>(<span class="st">&quot;csv&quot;</span>).option(<span class="st">&quot;header&quot;</span>,<span class="st">&quot;true&quot;</span>).option(<span class="st">&quot;inferSchema&quot;</span>, <span class="st">&quot;true&quot;</span>).load(<span class="st">&quot;Spark-The-Definitive-Guide/data/retail-data/by-day/2010-12-01.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" title="2">df.printSchema()</a>
<a class="sourceLine" id="cb1-3" title="3">df.createOrReplaceTempView(<span class="st">&quot;dfTable&quot;</span>)</a></code></pre></div>
</div><div id="schema-output" class="slide section level2">
<h1>Schema Output</h1>
<pre><code>&gt;&gt;&gt; df.printSchema()
root
 |-- InvoiceNo: string (nullable = true)
 |-- StockCode: string (nullable = true)
 |-- Description: string (nullable = true)
 |-- Quantity: integer (nullable = true)
 |-- InvoiceDate: timestamp (nullable = true)
 |-- UnitPrice: double (nullable = true)
 |-- CustomerID: double (nullable = true)
 |-- Country: string (nullable = true)</code></pre>
</div><div id="booleans" class="slide section level2">
<h1>Booleans</h1>
<ul class="incremental">
<li>You can build logical statements to evaluate either <em>true</em> or <em>false</em>
<ul class="incremental">
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col</code></li>
<li><code class="sourceCode python">df.where(col(<span class="st">&quot;InvoiceNo&quot;</span>) <span class="op">!=</span> <span class="dv">536365</span>).select(<span class="st">&quot;InvoiceNo&quot;</span>, <span class="st">&quot;Description&quot;</span>).show(<span class="dv">5</span>, <span class="va">False</span>)</code></li>
</ul></li>
<li>A cleaner solution would be to specify a predicate as an expression in a string
<ul class="incremental">
<li>Another way to say <em>does not equal</em></li>
<li><code class="sourceCode python">df.where(<span class="st">&quot;InvoiceNo &lt;&gt; 536365&quot;</span>).show(<span class="dv">5</span>, <span class="va">False</span>)</code></li>
</ul></li>
<li>In Spark, you should always chain together <code>and</code> filers
<ul class="incremental">
<li>Even if filters are expressed serially, Spark will flatten all of these filters into one statement and performed the filter at the same time</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> instr</a>
<a class="sourceLine" id="cb3-2" title="2">priceFilter <span class="op">=</span> col(<span class="st">&quot;UnitPrice&quot;</span>) <span class="op">&gt;</span> <span class="dv">600</span></a>
<a class="sourceLine" id="cb3-3" title="3">descripFilter <span class="op">=</span> instr(df.Description, <span class="st">&quot;POSTAGE&quot;</span>) <span class="op">&gt;=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb3-4" title="4">df.where(df.StockCode.isin(<span class="st">&quot;DOT&quot;</span>)).where(priceFilter <span class="op">|</span> descripFilter).show()</a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode sql"><code class="sourceCode sql"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> dfTable <span class="kw">WHERE</span> StockCode <span class="kw">in</span> (<span class="ot">&quot;DOT&quot;</span>) <span class="kw">AND</span> (UnitPrice <span class="op">&gt;</span> <span class="dv">600</span> <span class="kw">OR</span> <span class="fu">instr</span>(Description, <span class="ot">&quot;POSTAGE&quot;</span>) <span class="op">&gt;=</span> <span class="dv">1</span>)</a></code></pre></div>
</div><div id="boolean-column" class="slide section level2">
<h1>Boolean Column</h1>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> instr</a>
<a class="sourceLine" id="cb5-2" title="2">DOTCodeFilter <span class="op">=</span> col(<span class="st">&quot;StockCode&quot;</span>) <span class="op">==</span> <span class="st">&quot;DOT&quot;</span></a>
<a class="sourceLine" id="cb5-3" title="3">priceFilter <span class="op">=</span> col(<span class="st">&quot;UnitPrice&quot;</span>) <span class="op">&gt;</span> <span class="dv">600</span></a>
<a class="sourceLine" id="cb5-4" title="4">descripFilter <span class="op">=</span> instr(col(<span class="st">&quot;Description&quot;</span>), <span class="st">&quot;POSTAGE&quot;</span>) <span class="op">&gt;=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb5-5" title="5">df.withColumn(<span class="st">&quot;isExpensive&quot;</span>, DOTCodeFilter <span class="op">&amp;</span> (priceFilter <span class="op">|</span> descripFilter)).where(<span class="st">&quot;isExpensive&quot;</span>).select(<span class="st">&quot;unitPrice&quot;</span>,<span class="st">&quot;isExpensive&quot;</span>).show(<span class="dv">5</span>)</a></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode sql"><code class="sourceCode sql"><a class="sourceLine" id="cb6-1" title="1"><span class="co">--in SQL</span></a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw">SELECT</span> UnitPrice, (StockCode <span class="op">=</span> <span class="st">&#39;DOT&#39;</span> <span class="kw">AND</span> (UnitPrice <span class="op">&gt;</span> <span class="dv">600</span> <span class="kw">or</span> <span class="fu">instr</span>(Description, <span class="ot">&quot;POSTAGE&quot;</span>) <span class="op">&gt;=</span> <span class="dv">1</span>)) <span class="kw">as</span> isExpensive</a>
<a class="sourceLine" id="cb6-3" title="3"><span class="kw">FROM</span> dfTable</a>
<a class="sourceLine" id="cb6-4" title="4"><span class="kw">WHERE</span> (StockCode <span class="op">=</span> <span class="st">&#39;DOT&#39;</span> <span class="kw">AND</span> (UnitPrice <span class="op">&gt;</span> <span class="dv">600</span> <span class="kw">OR</span> <span class="fu">instr</span>(Description, <span class="ot">&quot;POSTAGE&quot;</span>) <span class="op">&gt;=</span> <span class="dv">1</span>))</a></code></pre></div>
</div><div id="working-with-numbers-and-nulls" class="slide section level2">
<h1>Working With Numbers and Nulls</h1>
<ul class="incremental">
<li>When using comparisons, watch out for Nulls
<ul class="incremental">
<li>There is a way to do a null-safe comparison</li>
<li><code class="sourceCode python">df.where(col(<span class="st">&quot;Description&quot;</span>).eqNullSafe(<span class="st">&quot;hello&quot;</span>)).show()</code></li>
</ul></li>
<li>Working with Big Data, after you filter things (WHERE clause), the next task is to count things</li>
<li>We are able to do math on numeric typed fields, such as:
<ul class="incremental">
<li>Exponents 82</li>
<li>Addition and subtraction</li>
<li>All of these features are available in SQL as well and can be written as <em>selectExpr</em></li>
<li>Rounding up by default, rounding down, truncating</li>
</ul></li>
</ul>
</div><div id="basic-anova" class="slide section level2">
<h1>Basic ANOVA</h1>
<ul class="incremental">
<li>Usually there a basic set of statistical methods that are always useful
<ul class="incremental">
<li>Calculate the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" title="Pearson&#39;s R Definition">Pearson Correlation</a></li>
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> corr</code></li>
<li><code class="sourceCode python">df.stat.corr(<span class="st">&quot;Quantity&quot;</span>, <span class="st">&quot;UnitPrice&quot;</span>)</code></li>
<li><code class="sourceCode python">df.select(corr(<span class="st">&quot;Quantity&quot;</span>, <span class="st">&quot;UnitPrice&quot;</span>)).show()</code></li>
</ul></li>
<li>You can use a single <code>describe()</code> method to generate the following:
<ul class="incremental">
<li>count</li>
<li>mean</li>
<li>Standard deviation</li>
<li>min and max</li>
<li><code class="sourceCode python">df.describe().show()</code></li>
</ul></li>
<li>These aggregations can be preformed by importing the individual libraries</li>
<li>Additional statistical functions are available in the <strong>StatFunctions</strong> Package
<ul class="incremental">
<li><a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions" title="Python StatFunction Library Reference Link">Python StatFunction Library Reference</a></li>
</ul></li>
</ul>
</div><div id="working-with-strings" class="slide section level2">
<h1>Working With Strings</h1>
<ul class="incremental">
<li>String manipulation is important because you might not have any guarantees about the data you are working with
<ul class="incremental">
<li>What if the data when entered didn’t have any capitalization enforcement?</li>
<li>How does this affect string comparisons?</li>
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> initcap</code></li>
<li><code class="sourceCode python">df.select(initcap(col(<span class="st">&quot;Description&quot;</span>))).show()</code></li>
<li><code>lower</code> and <code>upper</code> will cast entire strings</li>
<li>Trimming or padding whitespace 85</li>
<li>Regex (Regular Expressions)</li>
<li>Use the <code>contains</code> method on a column to return a <code>true</code> or <code>false</code></li>
<li>Python uses the <code>instr</code> function in place of <code>contains</code></li>
</ul></li>
</ul>
</div><div id="working-with-dates-and-timestamps" class="slide section level2">
<h1>Working With Dates and Timestamps</h1>
<ul class="incremental">
<li>Always challenging because they are numbers but not ordinal
<ul class="incremental">
<li>Sometimes dates are stored as strings because of this</li>
<li>Timezones and Daylight Saving time</li>
<li>Even though Spark uses Java dates and timestamps it only works to second level precision</li>
<li>No milliseconds</li>
<li>Java does have support for date addition and subtraction 91</li>
<li>Can also do date comparison and difference between two dates (number of days)</li>
<li><code>to_date</code> function allows for converting a string to a date (format can be specified)</li>
</ul></li>
</ul>
</div><div id="working-with-nulls" class="slide section level2">
<h1>Working With Nulls</h1>
<ul class="incremental">
<li>Nulls can be represent missing or empty data
<ul class="incremental">
<li>Spark is internally optimized for use of nulls as opposed to empty strings or zeros</li>
<li>But does using <em>nulls</em> make sense in your logic</li>
<li>Spark has built in functions to check for nulls</li>
<li>The <code class="sourceCode python">df.na.drop(<span class="st">&quot;any&quot;</span>)</code> can be used to drop any row in which any value is null</li>
<li><code>fill()</code> and <code>replace()</code></li>
</ul></li>
</ul>
</div><div id="conclusion" class="slide section level2">
<h1>Conclusion</h1>
<ul class="incremental">
<li>This chapter demonstrated how easy it is to extend Spark SQL and in a way that is easy to understand.</li>
</ul>
</div><div id="questions" class="slide section level2">
<h1>Questions</h1>
<ul class="incremental">
<li>Any questions?</li>
<li>Read Chapter 07 and do any exercises in the book.</li>
</ul>
</div>
</body>
</html>
